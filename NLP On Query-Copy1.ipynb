{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer('\\w+')\n",
    "ps = PorterStemmer()\n",
    "stopwords = []\n",
    "\n",
    "with open('All_Languages.txt' ,'r+',encoding='utf-8') as f:\n",
    "    l = f.readlines()\n",
    "new_l  =[]\n",
    "for i in l:\n",
    "    new_l.append(i[:-1])\n",
    "l = new_l\n",
    "\n",
    "with open(\"stopwords.txt\", 'r') as f:\n",
    "    stopwords = f.read()\n",
    "stopwords = stopwords.split(\"\\n\")\n",
    "\n",
    "sw = set(stopwords)\n",
    "\n",
    "def getStemReview(reviews):\n",
    "    review = reviews.lower()\n",
    "    \n",
    "    tokens = tokenizer.tokenize(review)\n",
    "    new_tokens = [w for w in tokens if w not in sw]\n",
    "    stemmed_token = [ps.stem(token) for token in new_tokens if token not in l]\n",
    "    \n",
    "    cleaned_review = ' '.join(stemmed_token)\n",
    "    return cleaned_review\n",
    "\n",
    "\n",
    "# Word And Sentence Tokenmization & Stop Removal \n",
    "def SentenceTokenization(text):\n",
    "    sentences = re.compile('[.!?] ').split(text)\n",
    "    return sentences\n",
    "\n",
    "def WordTokenization(sentence):\n",
    "    tokens = re.findall(\"[\\w']+\", sentence)\n",
    "    return tokens\n",
    "\n",
    "def StopWordRemoval(allwords):\n",
    "    stopwords = []\n",
    "    with open(\"stopwords.txt\", 'r') as f:\n",
    "        stopwords = f.read()\n",
    "    stopwords = stopwords.split(\"\\n\")\n",
    "    \n",
    "    usefull_words = [word for word in allwords if word not in stopwords]\n",
    "    return usefull_words\n",
    "\n",
    "# Stemming And Lemmatizing\n",
    "def StemmingAndLemmatizing(usefull_words):\n",
    "    ps = PorterStemmer()\n",
    "    \n",
    "    with open(\"All_Languages.txt\",\"r+\",encoding='utf-8') as f:\n",
    "        languages = f.read()\n",
    "        \n",
    "    keyword_extract = []\n",
    "    for i in range(len(usefull_words)):\n",
    "        for j in range(len(usefull_words[i])):\n",
    "            if usefull_words[i][j].lower() not in languages:\n",
    "                x = ps.stem(usefull_words[i][j])\n",
    "                usefull_words[i][j] = x\n",
    "            else:\n",
    "                keyword_extract.append(usefull_words[i][j])\n",
    "    return usefull_words,keyword_extract\n",
    "\n",
    "def nlp(text):\n",
    "    sentences = SentenceTokenization(text)\n",
    "\n",
    "    words = [] \n",
    "    for sentence in sentences:\n",
    "        words_in_a_sent = WordTokenization(sentence)\n",
    "        words.append(words_in_a_sent)\n",
    "\n",
    "    usefull_words = []\n",
    "    for words_in_a_sentence in words:\n",
    "        usefull_words_in_sent = StopWordRemoval(words_in_a_sentence)\n",
    "        usefull_words.append(usefull_words_in_sent)\n",
    "\n",
    "    usefull_words,keywords = StemmingAndLemmatizing(usefull_words)\n",
    "    return usefull_words,keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"DataSet3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3-frcr part 2b preparation course (latest edit...</td>\n",
       "      <td>2b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cissp practice tests - all domains - 2020 - 42...</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rhythm #1: intro - turn 8th note to 16th note ...</td>\n",
       "      <td>8th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sap abap programming for beginners - online tr...</td>\n",
       "      <td>abap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>debugging sap abap code for non programmers</td>\n",
       "      <td>abap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3885</th>\n",
       "      <td>introduction to μλ</td>\n",
       "      <td>μλ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3886</th>\n",
       "      <td>basics of μλ</td>\n",
       "      <td>μλ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3887</th>\n",
       "      <td>getting started with μλ</td>\n",
       "      <td>μλ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3888</th>\n",
       "      <td>roadmap for μλ</td>\n",
       "      <td>μλ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3889</th>\n",
       "      <td>i want to learn μλ</td>\n",
       "      <td>μλ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3890 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      X     y\n",
       "0     3-frcr part 2b preparation course (latest edit...    2b\n",
       "1     cissp practice tests - all domains - 2020 - 42...   420\n",
       "2     rhythm #1: intro - turn 8th note to 16th note ...   8th\n",
       "3     sap abap programming for beginners - online tr...  abap\n",
       "4           debugging sap abap code for non programmers  abap\n",
       "...                                                 ...   ...\n",
       "3885                                 introduction to μλ    μλ\n",
       "3886                                       basics of μλ    μλ\n",
       "3887                            getting started with μλ    μλ\n",
       "3888                                     roadmap for μλ    μλ\n",
       "3889                                 i want to learn μλ    μλ\n",
       "\n",
       "[3890 rows x 2 columns]"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = training_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train  = training_data.iloc[:,0].values,training_data.iloc[:,1].values\n",
    "# X_train = [\"Introduction to Android\",\"Introduction to angularjs\",\"Basics of Python\"]\n",
    "# y_train = [\"android\",\"angularjs\",\"python\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_train)):\n",
    "    X_train[i],keyword = nlp(X_train[i].lower())\n",
    "    X_train[i] = \" \".join(X_train[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(1,1))\n",
    "x_vec = cv.fit_transform(X_train).toarray()\n",
    "x_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict()\n",
    "rd= dict()\n",
    "for i in range(len(l)):\n",
    "    d[l[i]]=i\n",
    "    rd[i]= l[i]\n",
    "    \n",
    "y_train_num = []\n",
    "for i in range(len(y_train)):\n",
    "    y_train_num.append(d[y_train[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(x_vec,y_train_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = [\"roadmap to js \",\"i like android\",\"Basics of Python\",\"roadmap of javascript\",\"Getting Started with js\",\"I like kotlin not android\"]\n",
    "for i in range(len(x_test)):\n",
    "    x_test[i],keword = nlp(x_test[i].lower())\n",
    "    x_test[i] = \" \".join(x_test[i][0])\n",
    "x_text_vec = cv.transform(x_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[108  38 485 326 108 342]\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(x_text_vec)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch\n",
      "android\n",
      "python\n",
      "javascript\n",
      "batch\n",
      "kotlin\n"
     ]
    }
   ],
   "source": [
    "for i in y_pred:\n",
    "    print(rd[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
